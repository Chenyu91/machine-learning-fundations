1
00:00:00,000 --> 00:00:08,360
[音樂] [音樂]

2
00:00:08,360 --> 00:00:17,000
[音樂] [音樂]

3
00:00:17,000 --> 00:00:25,485
好，大家好，歡迎回到今天的機器學習課程， 那今天我們要跟大家講的課題是types

4
00:00:25,485 --> 00:00:30,040
of learning 就是各式各樣不同的機器學習問題。

5
00:00:30,040 --> 00:00:38,620
那我相信我們講到現在，大家對機器學習的基本流程
以及我們可以使用的一些非常基本的元件，有非常

6
00:00:38,620 --> 00:00:44,361
具體的瞭解，例如說，我們上一次講到說，在我們如果要回答yes, no

7
00:00:44,361 --> 00:00:48,188
是非題的時候呢，那我們可以 使用像perceptrons

8
00:00:48,188 --> 00:00:54,450
learning
algorithm這樣的演算法，它會在所有各式各樣，無限多條線裏面，幫我們找一條符合

9
00:00:54,450 --> 00:01:01,600
我們資料的特性的最好的線。那今天呢，我們從這裡出發，我們說，我們現在已經會做這樣的-
是非題了，

10
00:01:01,600 --> 00:01:10,400
那我們還要探討說，在會做這樣的是非題之後，在機器學習裏面
還有哪些其他的問題，它跟我們以前會做的這樣的是非題

11
00:01:10,400 --> 00:01:15,710
有些什麽不一樣。好，那在哪邊不一樣，我們會一項一項再跟大家提到。

12
00:01:15,710 --> 00:01:23,710
好，所以我們複習一下是非題是什麼樣的，我們上一次舉的例子是如果今天一個銀行要決定，

13
00:01:23,710 --> 00:01:32,570
要不要發信用卡，給它的這個顧客，那麼我們就有顧客的
資料，然後我們希望最終最終，機器學習從這些顧客的資料裏面，

14
00:01:32,570 --> 00:01:40,350
好我們把顧客的資料喂進去一個Hypothesis我們叫做G，然後這個G會告訴我們說-
要不要給這個顧客信用卡，

15
00:01:40,350 --> 00:01:49,860
你要做這件事呢，我們喂給機器的資料是什麽，我們之前有
這個甲顧客，給了他信用卡，乙顧客我們不要給他信用卡，丙顧客

16
00:01:49,860 --> 00:01:55,704
我們怎麼樣？好，張三怎麼樣，李四怎麼樣？然後我們把這些資料喂給機器，
機器從裏面，可以用percentrons

17
00:01:55,704 --> 00:02:02,389
learning
algorithm去找出一個線性的分類器。然後最後，來決定說未來的顧客，我們要不要-

18
00:02:02,389 --> 00:02:07,280
給信用卡， 好，那像這樣，答案只有兩種可能性，

19
00:02:07,280 --> 00:02:11,450
要，或不要的，我們把它叫做binary classification。一般我們把它

20
00:02:11,450 --> 00:02:17,437
叫做二元分類，簡單來說就是是非題，好，我們想要的這個Hypothesis g

21
00:02:17,437 --> 00:02:27,320
或者我們最想要的那個 f， 好，兩個的輸出都是在這個Y
這個輸出的空間里面。那它只有兩種可能性，我一般習慣用負1跟

22
00:02:27,320 --> 00:02:35,120
正1，好，這是是非題。是非題的應用非常的廣泛，大家現在腦袋里應該有一個基本的觀念，-
說我們現在讓電腦做

23
00:02:35,120 --> 00:02:42,920
是非題，就好像上面這三個圖一樣，我們喂給電腦的資料是圖上的那些藍色的圈圈，或者是紅-
色的叉叉，

24
00:02:42,920 --> 00:02:50,695
電腦的任務，是去找出一條線，這一條線會把整個這個平面或者空間分成兩個區域，一個區域

25
00:02:50,695 --> 00:02:58,470
是藍色的，一個區域是紅色，這代表說未來在這個區域裏面的點，機器會預測藍色的說好，或-
者紅色的說不好。

26
00:02:58,470 --> 00:03:07,310
那我們之後會學到用各種不一樣的方式，不一定是直線啊，
也許是曲綫，也許是更複雜的曲綫，來分割這兩個區域，

27
00:03:07,310 --> 00:03:13,110
那binary classification
這個二元分類的問題呢，在很多地方都有應用，例如說，我們說

28
00:03:13,110 --> 00:03:18,910
這個決定要不要發信用卡，要發，不要發。這是兩個不同的輸出。

29
00:03:18,910 --> 00:03:24,380
那你的電子郵件，是垃圾郵件，不是垃圾郵件，這是兩個不同的選項。

30
00:03:24,380 --> 00:03:29,685
那如果這一個病人，有生病，沒有生病，這是兩個不同的選項。那或者

31
00:03:29,685 --> 00:03:34,990
是說，這個今天你有一個廣告，它會賺錢，不會賺錢，這是兩個不同的這個

32
00:03:34,990 --> 00:03:42,990
輸出。那又或者是說，今天我們學生在一個答題系統裏面，他下一題，會答對，或者不會答對-
，這是兩

33
00:03:42,990 --> 00:03:49,330
個不同的輸出。那我們可以看到說，最後一個，實際上就是我之前跟大家提到過我們在
KDDCup

34
00:03:49,330 --> 00:03:53,720
這樣的比賽裏面，我們需要面對，需要去解決的問題。

35
00:03:53,720 --> 00:03:59,984
好，這是binary classification，我們未來會慢慢學到說binary
classification

36
00:03:59,984 --> 00:04:06,467
二元分類這個問題呢，
實際上在機器學習裏面，非常的基本，我們很多的理論的推導還有實際的演算法，都是從bi-

37
00:04:06,467 --> 00:04:15,190
nary classification
出發，那我們可以從有點像會答是非題，你才會答其他各式各樣不同更複雜的題目，

38
00:04:15,190 --> 00:04:19,130
所以它是機器學習裏面，一個非常核心的問題。

39
00:04:19,130 --> 00:04:27,590
從是非題出發呢，一個延伸的 問題就是，如果我們今天，不是要把東西分成兩類，

40
00:04:27,590 --> 00:04:34,940
例如說我這邊 show 給大家一個簡單的圖釋，我們想要把我們手上的銅板分成四類，

41
00:04:34,940 --> 00:04:41,080
什麽地方會用到這個問題，大家其實搞不好都已經用過了，你如果去販賣機，投飲料的時候，

42
00:04:41,080 --> 00:04:47,220
飲料的販賣機，就是嘗試著把你投進去的銅板分成好多個不同的類別。好，

43
00:04:47,220 --> 00:04:55,955
那這裡我們是用這個美國的錢來做例子，在美國的錢裏面大家在知道說，
最基本的銅板實際上是四種：1 cent, 5 cent,

44
00:04:55,955 --> 00:05:01,140
然後 10 cent,
25 cent，25 cent他們通常也叫quarter，是四分之一塊的意思，

45
00:05:01,140 --> 00:05:06,718
好，那如果有看過美國銅板的同學可能知道，它其實呢， 10

46
00:05:06,718 --> 00:05:11,777
cent的很奇怪，就是說它這個不是按照大小順序排列的， 10

47
00:05:11,777 --> 00:05:17,625
cent是所有的硬幣裏面最小的一顆，同樣重量也是最輕的一顆，所以

48
00:05:17,625 --> 00:05:27,246
如果我們把所有我們手上的銅板呢，按照它的這個大小，大小可能是這個半徑的大小，
還有它的重量劃的話，我們看到說10

49
00:05:27,246 --> 00:05:35,890
cent在這個最小，也是最輕的這個 左下角這邊。然後再來才是1
cent，然後5 cent，25 cent的是這個最大，然後最重的。

50
00:05:35,890 --> 00:05:43,847
所以大概，有這樣子的關係，好，所以如果，我們說，我們喂給電腦一些資料說，
好，這個重量這個大小的是10

51
00:05:43,847 --> 00:05:48,563
cent，這個重量、這個大小的是1 cent，這個重量、這個大小 的是5

52
00:05:48,563 --> 00:05:56,980
cent，然後我們希望說，好，那電腦你能不能
做出一個G，這個G可以讓我用在什麽，可以用在以後的販賣機裏面，

53
00:05:56,980 --> 00:06:06,325
能夠很精確地判斷說，使用投進去的銅板到底是哪一種，
這樣的問題呢，也就是說，我們的輸出，不再

54
00:06:06,325 --> 00:06:10,600
是兩種，現在是四種， 1 cent， 5
cent， 10 cent，25 cent。

55
00:06:10,600 --> 00:06:17,250
或者呢，抽象的來說，就是我們可以把它想成有K種，或可能用1，2，3，4一直到K
來表示，

56
00:06:17,250 --> 00:06:23,900
第一類，第二類，一路到第K類，在這個例子裏面，K是四，也就是說有四種不同的類別。

57
00:06:23,900 --> 00:06:30,780
好，這樣的問題呢，就比我們剛才原來的這個二元分類，要更

58
00:06:30,780 --> 00:06:39,730
一般化一些，就是有更多
可能性，實際上，二元分類，就是剛才那個問題的一個特殊的例子，說我只有兩個類

59
00:06:39,730 --> 00:06:48,000
的時候，那我們現在有很多類，我們一般把這個東西叫做 Multiclass
Classification，也就是多元的分類問題，

60
00:06:48,000 --> 00:06:56,000
或者呢，用一個比較通俗的說法，就是做選擇題，單選題，大家可能都做過單選題，1，2，-
3，4四個選項你要

61
00:06:56,000 --> 00:07:04,740
選一個正確的，現在不再是是非題，圈或叉兩個選項，現在是1，2，3，4四個
選項。或1，2，3，4，5 五個選項，你要從裏面，選一個正確的東西。

62
00:07:04,740 --> 00:07:09,935
好，那有什麽樣的這個應用，可以用這個

63
00:07:09,935 --> 00:07:15,130
多類別的這個分類問題呢，例如說，我們最常見的，我寫一個數字，

64
00:07:15,130 --> 00:07:22,710
電腦要幫我區分就說，我寫的數字到底是0，1，2
還是到9，那在什麽地方會用？郵遞區號的辨識

65
00:07:22,710 --> 00:07:31,350
就會用到這一個。我有一張圖，這張圖裏面有一個水果，請
電腦告訴我說，裏面到底是哪一種水果，是蘋果，還是橘子，還是草莓，

66
00:07:31,350 --> 00:07:39,350
好這是一個簡單的應用，各種不同的類別。那又或者你的電子郵件，現在我不是只有分說是正-
常的郵件還是垃圾郵件，

67
00:07:39,350 --> 00:07:47,580
我現在要分說，你是垃圾郵件，是重要的，是 這個社交的，還是說是有什麽促銷活動的，

68
00:07:47,580 --> 00:07:53,760
還是只是一些這個基本的更新。好，那這也是多類別分類，實際上最近，

69
00:07:53,760 --> 00:07:59,940
如果大家有用Google的電子郵件信箱的話，會發現Google正在推這樣的電子郵-
件信箱，

70
00:07:59,940 --> 00:08:03,990
它自動的幫你把進來的郵件分成，這樣的幾個類別。

71
00:08:03,990 --> 00:08:10,885
好，所以我們看到說這個多類別的分類問題，也有非常多的應用，實際上在哪邊

72
00:08:10,885 --> 00:08:17,780
應用最多呢，一個非常多應用的領域就是Recognition
就是視覺或者是聽覺的辨識。因為就像我們剛才所舉的例子，

73
00:08:17,780 --> 00:08:21,870
視覺的辨識，你的物體就是很多個不同的類別。

74
00:08:21,870 --> 00:08:31,320
好，那現在我們學了
兩個基本的問題了，一個是二元的分類，一個是更延伸的多元的分類問題，

75
00:08:31,320 --> 00:08:37,425
那這些問題，例如說，如果我們放在一個這個醫院的裏面的話，我們可以解決什麽問題呢？好-
，二元分類可能

76
00:08:37,425 --> 00:08:43,530
可以解決說，我告訴你一個病人的狀況，然後電腦自動說，他到底是生病，還是沒有生病。

77
00:08:43,530 --> 00:08:51,500
或者多元分類可能是我告訴，我告訴電腦說這個病人狀況怎麼樣，它告訴我說，他得的是哪一-
種癌癥，

78
00:08:51,500 --> 00:08:58,170
還是沒有癌癥。那還有一些其他的問題，例如說什麽，例如說，如果

79
00:08:58,170 --> 00:09:04,840
我們今天給了病人的狀況，我們想要知道的是，就是說是病人可能剛開完刀，他到底要多久，

80
00:09:04,840 --> 00:09:14,200
才可以恢復，才可以出院。好，這樣的問題的輸出是什麽，
我們想要知道幾天嘛，或者幾個小時，幾秒，這樣的數字，

81
00:09:14,200 --> 00:09:22,250
那這樣的數字的輸出，也就相對應到什麽，它的輸出
的空間，我們叫大Y，這個大Y實際上是整個實數，

82
00:09:22,250 --> 00:09:30,080
或者有些應用的例子裏面，它大Y
的輸出可能是某一個這個範圍，例如說，我今天要給學生打分數，我的

83
00:09:30,080 --> 00:09:37,910
分數的範圍可能是0分到100分，我不能幫大家打超過100分，也不能扣到小於0分，所-
以，我希望的輸出，

84
00:09:37,910 --> 00:09:47,006
可能是在一個範圍裏面，那這樣的問題，傳統的統計裏面，
通常叫做回歸分析Regression，Regression這個字的翻譯通常是迴-

85
00:09:47,006 --> 00:09:52,920
歸分析， 那如果是有範圍限制的話，叫做bounded
regression有範圍的，這個迴歸分析。

86
00:09:52,920 --> 00:10:00,920
那統計學裏面是一個非常非常傳統的問題，那有的同學可能有學過說線性回歸在統計或者一些

87
00:10:00,920 --> 00:10:05,930
一些相關的課程裡面學過線性回歸，線性回歸實際上就是一個典型的

88
00:10:05,930 --> 00:10:10,940
迴歸分析問題。那我們之後也會用機器學習的觀點跟大家提到這個問題。

89
00:10:10,940 --> 00:10:17,215
迴歸分析可以用在哪裡？比如說，我有一個機器，說這個

90
00:10:17,215 --> 00:10:23,490
這個公司的資料怎麼樣？或它的股票之前資料怎麼樣？我要預測什麼？我要預測它的明天的

91
00:10:23,490 --> 00:10:29,930
股票價格怎麼樣。或者是，你今天說得大氣的。我喂一些天氣的資料給

92
00:10:29,930 --> 00:10:37,590
機器，它分析了以後，那我能不能預測明天的氣溫是多少。那這些都是典型的迴歸分析的問題。

93
00:10:37,590 --> 00:10:41,570
它的特點就是輸出要是一值實數。

94
00:10:41,570 --> 00:10:49,570
那因為這個問題在統計裡面其實已經被研究了好幾十年了，所以有很多非常好的工具。

95
00:10:49,570 --> 00:10:58,000
那我們之後也會看到說這些工具常常也被
用在機器學習上面，或是用在建構更複雜的機器學習的

96
00:10:58,000 --> 00:11:02,500
演算法。所以它在機器學習裡面也是一個非常核心的問題。

97
00:11:02,500 --> 00:11:09,160
剛才都是一些簡單的輸出，那我們來想一些複雜的。

98
00:11:09,160 --> 00:11:14,740
如果我今天要用機器學習來做一件事，做所謂的自然語言辨識。

99
00:11:14,740 --> 00:11:21,225
自然語言辨識裡面的其中一個小問題就是我講或我寫出

100
00:11:21,225 --> 00:11:27,710
一段話的時候，我能不能知道我寫出來這段話裡面每一個字的詞性是甚麼?

101
00:11:27,710 --> 00:11:32,295
現在我左邊列了一句話，I love ML，那這個 I

102
00:11:32,295 --> 00:11:36,880
大家知道是代名詞。love是動詞，然後ML是一個名詞。

103
00:11:36,880 --> 00:11:42,650
所以自動的詞性標註是自然語言處理裡面相當重要的一個

104
00:11:42,650 --> 00:11:51,290
小問題。我們可以把這個問題看成是這個
multiclass，就是多類別的分類問題。我就只是要把每個字

105
00:11:51,290 --> 00:11:58,880
標成各種不同的這個詞性，所以我詞性可能有四個、五個、六個，那我把每個字標成各種不同-
的詞性。

106
00:11:58,880 --> 00:12:03,980
好像是個多類別的問題，但是如果我們現在問題的

107
00:12:03,980 --> 00:12:09,080
輸入不是以字，不是以WORD為單位，我們的X，大家記得我們的輸入嗎?

108
00:12:09,080 --> 00:12:14,010
如果不是以WORD為單位，而是以整個句子為單位的話，

109
00:12:14,010 --> 00:12:21,475
比如說，大家想像句子裡面可能是有某一種結構，某一種組織的。如果整個句子送進去，

110
00:12:21,475 --> 00:12:28,940
它就可能比較不容易判斷出來說這個詞到底是甚麼樣意思，對不對?例如說love這個字，-
它可能是動詞，可能是名詞。

111
00:12:28,940 --> 00:12:38,120
但是如果它今天放在一個名詞的後面，那可能比較可能是
動詞。所以會有句子結構上的東西，所以如果我們輸入是一個句子，

112
00:12:38,120 --> 00:12:42,345
然後我們的輸出呢?我們的輸出還是說每個字的詞性是甚麼?

113
00:12:42,345 --> 00:12:46,570
但是每個字的詞性串起來就是一個結構。

114
00:12:46,570 --> 00:12:49,970
所以在這個例子裏面，我們可能的輸出是甚麼?

115
00:12:49,970 --> 00:12:56,150
我們可能的輸出是這樣，例如說，今天如果是一個代名詞，再一個動詞，再一個名詞。

116
00:12:56,150 --> 00:13:02,160
這是一個正確的英文句子，今天是一個代名詞，一個動詞，一個代名詞，這也是一個正確的

117
00:13:02,160 --> 00:13:11,860
句子。或者今天是一個代名詞，一個動詞，如果今天是一個不及物動詞的話，那也是一個
正確的句子。所以有一些些正確句子的可能性，

118
00:13:11,860 --> 00:13:16,790
但是例如說，我們就不會把一個句子說成甚麼?說成連續五個動詞。

119
00:13:16,790 --> 00:13:21,720
連續五個動詞你就會知道這個句子一定沒有正確的英文文法在。

120
00:13:21,720 --> 00:13:29,650
所以這樣的問題，我們要怎麼從一個句子，然後標出句子裡面每一個詞的字，這樣的問題。

121
00:13:29,650 --> 00:13:32,990
我可以想成一個很大很大的多類別分類問題，

122
00:13:32,990 --> 00:13:40,990
只是現在的類別是藏在下面的，而且它很大很大。然後這些藏在下面的類別之間有某一種

123
00:13:40,990 --> 00:13:49,370
結構上的關係，我們並很難很難說我把所有 可能正確的句子窮極出來，因為它跟句子的長度

124
00:13:49,370 --> 00:13:56,980
等等的有關係。但是我們知道，它這裡面有某些結構的特性，這是我們希望電腦輸出的東西。

125
00:13:56,980 --> 00:14:01,240
大家可以想像說這樣的輸出實際上很複雜。

126
00:14:01,240 --> 00:14:06,320
但是應用其實也不少，例如說甚麼?今天如果有做生醫研究人員

127
00:14:06,320 --> 00:14:11,400
可能知道你希望會給電腦甚麼?會給它蛋白質的一些資料，那電腦告訴你甚麼?

128
00:14:11,400 --> 00:14:18,250
告訴你說這個蛋白質3D立體的長相是甚麼樣子的，做生物人員就會知道這個3D立體長相

129
00:14:18,250 --> 00:14:25,100
例如這邊彎一彎，這邊折一下會影醒到這個蛋白質到底會怎麼跟生物體實際上發生

130
00:14:25,100 --> 00:14:31,435
作用。或者今天如果是比較像自然語言處理這樣的問題說我講一段話，然後

131
00:14:31,435 --> 00:14:37,770
我要怎麼樣把這個話來弄成我們叫 part stream，我講的每一個字到底

132
00:14:37,770 --> 00:14:46,220
這個在話裡面這個關係是甚麼?那這樣的輸出
這樣比較複雜的輸出，通通可以看作我們這個問題

133
00:14:46,220 --> 00:14:52,705
我們叫做structure
learning，就是說結構化的學習。實際上代表的意思是我們要

134
00:14:52,705 --> 00:14:59,190
輸出空間，用某一種結構在裡面，希望電腦想辦法去學到這些結構。

135
00:14:59,190 --> 00:15:05,545
大家可以想像到這是一個很複雜的問題，它的一些解法實際上都是從多類別的

136
00:15:05,545 --> 00:15:11,900
分類問題延伸出來的。我之所以要提這個問題並不是說我們這個課裡面真的會教具體的方法去-
解決它。

137
00:15:11,900 --> 00:15:18,320
我只是要告訴大家說實際上機器學習不是只有做做簡單的是非題或者多類別分類。

138
00:15:18,320 --> 00:15:27,680
實際上還有滿複雜的問題，然後你真的在應用的時候，搞不好你會需要
滿複雜的問題。那那個時候，你會知道它跟其他問題之間的關聯性是甚麼。

139
00:15:27,680 --> 00:15:37,220
所以我們簡單複習一下， 我們會做的是非題，從是非題我們延伸到多類別的分類問題。

140
00:15:37,220 --> 00:15:43,210
然後另外一個核心的問題是迴歸分析，迴歸分析實際上就是我們要輸出實數，

141
00:15:43,210 --> 00:15:49,200
或者有點像我們的輸出空間就是無限大個各式各樣不同的實數。

142
00:15:49,200 --> 00:15:54,630
然後如果從多類別的問題再分出來是說我們可以做

143
00:15:54,630 --> 00:16:00,060
這些結構的學習。但這些結構的學習會很像一個很大的多類別分類問題。

144
00:16:00,060 --> 00:16:03,330
就是我們不是真正的把我們每個類別寫下來。

145
00:16:03,330 --> 00:16:11,310
這裡面最核心的工具是是非題還有迴歸分析。那我們之後會跟大家講比較多

146
00:16:11,310 --> 00:16:20,870
是非題跟迴歸分析的工具，那這些工具我們未來會跟大家提到說
它可能可以用來建構很多更複雜的工具來解決

147
00:16:20,870 --> 00:16:29,940
別的問題。那機器學習當然不是只有這四個，我舉一些重要的
只是給大家一個概念說我們可以變化各種不同的大Y。

148
00:16:29,940 --> 00:16:35,090
這個輸出空間的種類，然後就會有一個不同的機器學習的問題出來。

149
00:16:35,090 --> 00:16:43,430
那講到這樣我們就跟大家出個 小題目。大家想想看，我今天如果是一個學校，

150
00:16:43,430 --> 00:16:48,640
它的體育館要做一個門禁系統。門禁系統是判斷四種不同的

151
00:16:48,640 --> 00:16:54,630
訪客，這四種不同的訪客要收不一樣的錢，或者要不一樣的福利...等等。

152
00:16:54,630 --> 00:17:02,180
那麼它要做這樣的判斷，它想要用一個機器學習的系統來做自動的臉部辨識

153
00:17:02,180 --> 00:17:07,210
然後來做這樣的判斷。請問它對應到哪一種機器學習的問題?

154
00:17:07,210 --> 00:17:14,540
想一想之後，我希望大家都能夠想到正確的答案。這是一個典型的

155
00:17:14,540 --> 00:17:21,870
多類別分類。我們要分成四類，而且我們要真正能夠把這四類寫下來，並不是說我們有甚麼隱-
藏的結構在這裡面。

156
00:17:21,870 --> 00:17:26,450
那這是一個四個類別的多類別分類問題。

