1
00:00:00,000 --> 00:00:08,380
[音樂] [音樂]

2
00:00:08,380 --> 00:00:16,980
[音樂] [音樂]

3
00:00:16,980 --> 00:00:22,090
好 大家好 大家好 歡迎來到今天的機器學習課程

4
00:00:22,090 --> 00:00:29,250
那今天我們要從上一次的故事繼續下去 我們上一次跟大家介紹了一個具體的機器學習的問題

5
00:00:29,250 --> 00:00:35,475
然後以及他的內容的設定 那我們今天要繼續下去做什麼呢？ 我們今天要教大家說

6
00:00:35,475 --> 00:00:41,825
到底我們怎麼樣可以 有一個機器學習的演算法來解決我們上一次提到的

7
00:00:41,825 --> 00:00:48,858
要判斷銀行要不要給顧客信用卡這樣的問題 那麼複習一下我們上一次上了什麼

8
00:00:48,858 --> 00:00:54,217
我們上一次說機器學習做的事情就是 有一個學習的演算法 我們叫做A

9
00:00:54,217 --> 00:01:01,928
這個驗算法呢會看兩件事情 一件事情是什麼 是資料
我們叫做D 另外一件事情是一個hypothesis

10
00:01:01,928 --> 00:01:07,930
set 這個這個假說的集合 那他要從這個hypothesis set裡面選一個

11
00:01:07,930 --> 00:01:14,230
這個G 這個G會當做譬如說銀行最後使用的公式來這個

12
00:01:14,230 --> 00:01:21,015
等於是學到的一個這個技能 好 那我們今天會來講講說到底機器

13
00:01:21,015 --> 00:01:26,154
怎麼樣決定要不要發信用卡這一件事情 或者 更廣義的來說

14
00:01:26,154 --> 00:01:32,015
機器怎麼解決這種 是非的題目 就像這個我們考試的時候

15
00:01:32,015 --> 00:01:37,835
在做是非題一樣 我們今天要來學的是 怎麼樣的機器學習演算法 可以做是非題

16
00:01:37,835 --> 00:01:42,650
好 所以我們稍微複習一下 我們上一次整個

17
00:01:42,650 --> 00:01:47,854
機器學習的流程圖是怎麼樣 我們說 我們是從資料出發 那我們一個假設

18
00:01:47,854 --> 00:01:54,635
資料從哪裡來的 資料從一個我們想學 但是我們不知道的這個公式

19
00:01:54,635 --> 00:02:00,200
叫做F來的 我們有了這個資料以後 我們把這個資料餵給機器學習的演算法

20
00:02:00,200 --> 00:02:06,635
那這個演算法 幫助我們做的事情是什麼 看這些資料 然後從所有的可能性

21
00:02:06,635 --> 00:02:11,241
所有可能性 我們叫做大H 從所有大H裡面選一個G出來 然後

22
00:02:11,241 --> 00:02:18,086
我們的希望是G要跟我們的想要的F這個越接近越好 那我們用這個信用卡的例子來做比喻說

23
00:02:18,086 --> 00:02:22,800
那如果今天我們有一個信用卡的 申請人過來的時候 我們希望

24
00:02:22,800 --> 00:02:28,935
這個申請人我們用這個小寫x來表示 我們希望這個最後的G能夠決定說

25
00:02:28,935 --> 00:02:33,650
看了這個x 那它到底要給他信用卡還是不給他信用卡

26
00:02:33,650 --> 00:02:38,948
我們用這個小寫的y來表示說要給還是不給 的這件事情

27
00:02:38,948 --> 00:02:44,916
好 這是我們上一次提到的這個機器學習的設定 那我們現在進入什麼呢

28
00:02:44,916 --> 00:02:51,450
我們現在進入說 好吧 那麼我們的大H到底會長什麼樣子

29
00:02:51,450 --> 00:02:59,281
我們上一次只是很泛泛地講說 這些大H可能可以選
我們今天要跟大家介紹一個具體的大H的長相 好

30
00:02:59,281 --> 00:03:04,830
那我這邊就來跟大家介紹一個模型 這個模型是說我們

31
00:03:04,830 --> 00:03:10,620
怎麼樣拿到這個一組使用者的資料 我們怎麼樣評定要不要給他信用卡

32
00:03:10,620 --> 00:03:15,950
我們可以把每一個使用者用一個向量來表示 我們說每一個使用者叫做x

33
00:03:15,950 --> 00:03:21,070
我們可以把這個x想成一個向量 有好多個維度的向量 那例如說 第一個維度可能是他的

34
00:03:21,070 --> 00:03:26,190
這個年紀 第二個維度可能是他的年薪 第三個維度可能是他在

35
00:03:26,190 --> 00:03:31,284
工作有幾年了 那每個維度可能對我們有不同正面或負面的這個影響

36
00:03:31,284 --> 00:03:36,445
決定說到底我們想不想給他信用卡 那我們想做的事情是這樣

37
00:03:36,445 --> 00:03:43,530
我們把這些維度綜合地算起來 給使用者一個分數 然後呢這個分數會怎麼樣呢

38
00:03:43,530 --> 00:03:49,050
如果這個分數超過了某個標準的話 我們就說 啊那給他信用卡沒有問題

39
00:03:49,050 --> 00:03:53,780
如果這個分數沒有超過某個標準的話 我們就說不要給他信用卡好了

40
00:03:53,780 --> 00:03:59,834
這就有點像你在考試的時候 那這個每一題每一個題目老師給你分數

41
00:03:59,834 --> 00:04:04,992
把這些分數加加起來 如果你超過六十分的話 老師就說 啊你及格了

42
00:04:04,992 --> 00:04:09,650
給你過關好了 如果沒有超過六十分 就說你不及格不要給你過關

43
00:04:09,650 --> 00:04:15,355
這是類似的意思 好 那有了這樣的模型 所以我們說 每一個維度

44
00:04:15,355 --> 00:04:20,533
我們說每一個維度我們用這個小Xi這個來代表 那它會乘上什麼呢

45
00:04:20,533 --> 00:04:26,115
乘上這個維度的這個重要性 如果今天這個維度對我們來說很重要 我們可能這個

46
00:04:26,115 --> 00:04:31,237
等於配分要多一點 如果這個維度對我們來說是這個正相關的

47
00:04:31,237 --> 00:04:36,819
那可能是正面的重要 如果這個維度對我們來說是負相關的 例如說他欠的錢很多

48
00:04:36,819 --> 00:04:43,820
那我們可能不要給他信用卡 那可能這個這裡的這個W會是這個負的或是比較小的 好

49
00:04:43,820 --> 00:04:49,360
總之 就是這些東西加加起來 然後我們看看他最後得到的

50
00:04:49,360 --> 00:04:55,070
分數幾分 好那在這樣的模型裡面呢 我們想像說 我們要做的事情是什麼

51
00:04:55,070 --> 00:05:00,780
我們要電腦自動告訴我們說 要給信用卡 給信用卡是好的 還是不給信用卡

52
00:05:00,780 --> 00:05:06,310
給信用卡是不好的 那我們當然可以用這個任意的這個數字或符號 來表示這件事情

53
00:05:06,310 --> 00:05:11,840
那這裡為了數學簡單起見 我們用兩個數字來代表好或不好

54
00:05:11,840 --> 00:05:20,420
好的我們叫+1 不好的我們叫-1 這樣表示有什麼好處呢
這樣表示的話 實際上我們發現一件事

55
00:05:20,420 --> 00:05:26,525
我們要電腦做的決定 就是 先算出這一串分數

56
00:05:26,525 --> 00:05:31,531
我們說這個W跟X 這些相乘這些分數通通算起來

57
00:05:31,531 --> 00:05:36,790
算起來之後 減掉我們所設定的這個標準 設定的這個門檻值

58
00:05:36,790 --> 00:05:42,425
然後怎麼樣 如果這個減掉以後是正的 我們就說 這個是好的 如果是負的

59
00:05:42,425 --> 00:05:47,710
我們就說是不好的 所以這個相對來說 實際上就是取一個這個sin這樣

60
00:05:47,710 --> 00:05:53,096
這個符號 可能是正負號的這個運算 所以我們就可以很簡潔的

61
00:05:53,096 --> 00:05:59,223
把我們想要做的事情是什麼 把使用者的資料呢拿來 透過W來做一個加權

62
00:05:59,223 --> 00:06:04,387
然後取一個總分 然後看看這個總分有沒有超出我們的門檻值

63
00:06:04,387 --> 00:06:09,510
超出來我們就給+1 沒有超出來我們就給 沒有 就給-1

64
00:06:09,510 --> 00:06:15,995
那你說 那如果剛好在門檻上面怎麼樣 通常這種事情很少發生

65
00:06:15,995 --> 00:06:21,262
我們可以想像說我們就當做 就就就是一個這個這個特例的狀況

66
00:06:21,262 --> 00:06:25,626
我們可以暫時不管它 事實上在我們未來講的故事裡面

67
00:06:25,626 --> 00:06:30,378
大部份的時候這個剛好在這個門檻值上的情形 沒什麼重要性

68
00:06:30,378 --> 00:06:36,363
或者是我們想像說不然那時候就丟個銅板決定好了 反正有時候是對的 有時候是錯的 好

69
00:06:36,363 --> 00:06:40,915
那這樣的模型 這樣的反紅

70
00:06:40,915 --> 00:06:45,880
有沒有注意到 我這裡用的是h 用的是小h 小h是什麼 小h是我們可能的公式

71
00:06:45,880 --> 00:06:51,391
這個小h跟什麼東西有關 跟W有關 跟我們選的門檻有關

72
00:06:51,391 --> 00:06:55,650
所以我們可以 不同的W 不同的門檻

73
00:06:55,650 --> 00:07:00,770
就造出不同的h 好 那這樣的h 在這個

74
00:07:00,770 --> 00:07:07,140
歷史上我們把這個叫做perceptron perceptron這個字
字面上的翻譯叫做感知器

75
00:07:07,140 --> 00:07:12,250
那這個字的來源實際上 是非常早期的類神經網路的這些研究出來的 就是說

76
00:07:12,250 --> 00:07:18,336
感知器就很像我們人體裡面的 一個神經元的數學模型一樣 我們這邊先不深究這件事情

77
00:07:18,336 --> 00:07:23,175
我們就是說 好所以這是我們的一個hypothesis 可以注意到

78
00:07:23,175 --> 00:07:28,290
hypothesis就是說電腦最後會猜測啊 猜測說是不是這是一個

79
00:07:28,290 --> 00:07:34,489
可能的公式的長相 那這個h會用什麼來決定 用W跟

80
00:07:34,489 --> 00:07:40,086
還有我們的 門檻值來決定 那這個W 通常我們會叫做位置

81
00:07:40,086 --> 00:07:45,558
就是這個權重 就是每一個這個維度的這個權重

82
00:07:45,558 --> 00:07:50,748
好 那所以我們的h長的是這樣 我們h是W

83
00:07:50,748 --> 00:07:57,440
用W算出來的一個分數 然後再減掉門檻值 然後再取這個正負號

84
00:07:57,440 --> 00:08:02,635
好你說這個 每次要寫這麼一長串很麻煩

85
00:08:02,635 --> 00:08:07,830
所以我們這邊呢稍微跟大家說 我們會做一個這個簡化的動作

86
00:08:07,830 --> 00:08:13,875
其實是符號上簡化 意思上沒有太簡化的地方 我們想要做什麼呢

87
00:08:13,875 --> 00:08:18,750
我們想要把這個門檻值 okay 也當成是一個特殊的W

88
00:08:18,750 --> 00:08:24,330
怎麼樣可以做到這件事情呢 大家看到說我們的這個式子 okay 這邊有這個W

89
00:08:24,330 --> 00:08:29,220
然後有這個門檻值 我們如果把門檻值 我們要減掉這個門檻值

90
00:08:29,220 --> 00:08:34,860
當做什麼呢 當作說 我們有一個這個負的

91
00:08:34,860 --> 00:08:39,260
門檻值的這個 這個維度 然後呢 有一個

92
00:08:39,260 --> 00:08:44,131
常數 這個常數叫做+1 然後順便把這個常數叫做X0 你說

93
00:08:44,131 --> 00:08:50,380
我這個小x原來是一維二維一直到D維 我現在把它生出一個第0維來

94
00:08:50,380 --> 00:08:55,832
生出一個第0維來有什麼好處 我就可以把這個負的門檻值

95
00:08:55,832 --> 00:09:00,598
這個同等的叫做W0 那我就可以怎麼樣

96
00:09:00,598 --> 00:09:05,560
我就可以把我原來這邊 前面有漂漂亮亮的WiXi

97
00:09:05,560 --> 00:09:12,730
我可以把這個W0X0 收進來WiXi這邊 只需要放一個summation

98
00:09:12,730 --> 00:09:17,908
放一個這個連加的這個符號 然後把連加的 起始點 從

99
00:09:17,908 --> 00:09:24,244
原來是從1開始 現在改成用0開始 好 那這只是我們符號上做了一個事情

100
00:09:24,244 --> 00:09:29,511
符號上做了這個事情有什麼好處呢 如果我今天把X 我們之前說X

101
00:09:29,511 --> 00:09:35,600
1維到D維 現在加了第0維 好 想成一個這個高高的這個向量

102
00:09:35,600 --> 00:09:43,818
那W我們也可以表示成一個高高的向量 所以這個summation這個連加的動作

103
00:09:43,818 --> 00:09:51,001
其實就是兩個高高的向量的內積而已 好
我們這是符號上的簡化 我們不想要寫一堆summation

104
00:09:51,001 --> 00:09:56,781
然後不想要特別寫一個 這個門檻值 所以我們就說 好 我們現在就想像 我們在處理什麼

105
00:09:56,781 --> 00:10:03,190
我們在處理X 是這個顧客的資料，這個X顧客的資料是一個高高的向量。除了原來的資料以外

106
00:10:03,190 --> 00:10:09,135
還有第0維。那w我們想要跟h所對應的這個w

107
00:10:09,135 --> 00:10:15,080
也是一個高高的向量，它也有一個第0維，它的第0維會對應到我們原先想要的

108
00:10:15,080 --> 00:10:20,215
負的這個門檻值。這只是一個符號。有了這個

109
00:10:20,215 --> 00:10:25,350
符號以後呢，那我們就可以對這個符號做一些數學上的操作。

110
00:10:25,350 --> 00:10:29,770
這樣子講大家可能還是覺得很抽象。

111
00:10:29,770 --> 00:10:37,520
幹嘛要這個冒出一個，原來顧客這個資料我們知道
那冒出一個W這個符號，然後又說有一個這個h。

112
00:10:37,520 --> 00:10:42,360
我們能不能有一些具體的想法說這個h長什麼樣子。

113
00:10:42,360 --> 00:10:47,730
眼見為憑，所以我們給大家看看這個h長什麼樣子。

114
00:10:47,730 --> 00:10:51,840
我們做什麼呢，我們畫一個二維的圖給大家看。

115
00:10:51,840 --> 00:10:58,810
這個二維的圖上是什麼樣呢？這個二維圖上我們原來的每個X是二維的。

116
00:10:58,810 --> 00:11:05,780
那如果我們加上這個剛才說X0那個維度的話，是一個這個假的這個三維，高高的這個向量。

117
00:11:05,780 --> 00:11:13,060
所以他其實就是有什麼，我們如果看每一個h(x)都長的這樣，它有一個W0

118
00:11:13,060 --> 00:11:18,940
有一個W1乘以x的第一個維度，有一個W2乘以x的第二個維度。

119
00:11:18,940 --> 00:11:23,630
任何一條這樣的h我們可以把它畫出來。

120
00:11:23,630 --> 00:11:28,320
像下面這樣畫出來，那麼怎麼畫呢？我給大家解釋一下。

121
00:11:28,320 --> 00:11:33,845
我們的每一個原來顧客的向量，是一個二維的向量。

122
00:11:33,845 --> 00:11:39,370
我們就把它們表示成平面上的一個點就是圈圈叉叉。統統都是一個點。

123
00:11:39,370 --> 00:11:46,690
如果我們有更多維，當然就是在這個O幾的空間裡面。更多維的點，二維的我們比較好看一點。

124
00:11:46,690 --> 00:11:53,590
那麼我們的Y在哪裡呢，我們想要的輸出，一般在資料裡面對應到想要輸出

125
00:11:53,590 --> 00:12:02,390
我們一般把它叫lable，標籤，這個標籤在哪裡呢？這個標籤
我們畫成圈圈，還是叉叉，圈圈代表我們想要正1。

126
00:12:02,390 --> 00:12:06,870
叉叉代表我們想要負1，圈圈代表正1叉叉代表負1。

127
00:12:06,870 --> 00:12:16,490
所以我們就把這個平面然後就把圈圈叉叉弄出來了，那h是什麼？
h大家看看說，我們在取符號對不對

128
00:12:16,490 --> 00:12:20,630
所以它的切換點是什麼，取正負號。

129
00:12:20,630 --> 00:12:28,460
切換點是中間這個值等於0的時候，這是它的切換點，從正切換到負，等於0的時候，從正-
切換到負

130
00:12:28,460 --> 00:12:33,835
那我今天有一個這個式子，這個式子是X1乘上什麼東西

131
00:12:33,835 --> 00:12:39,210
加X2乘上什麼東西，然後加上一個這個截距然後等於0。

132
00:12:39,210 --> 00:12:45,060
這在平面上是什麼？大家學過數學會說這就是條直線。

133
00:12:45,060 --> 00:12:51,320
所以我如果把h畫出來給大家看的話，就是一條直線。

134
00:12:51,320 --> 00:12:57,950
這條直線的一邊，這個h會說圈圈會說想要圈圈。

135
00:12:57,950 --> 00:13:03,540
會說預測成圈圈。這個h的另外一邊我們的線會說叉叉。

136
00:13:03,540 --> 00:13:08,810
所以我們的每個h實際上是對應到平面上面的一條線。

137
00:13:08,810 --> 00:13:14,500
我們的每個資料裡面的每個X對應到一個點，Y對應到說我們的這個點上

138
00:13:14,500 --> 00:13:20,190
畫圈圈還是叉叉。然後每個h我們剛才講的那樣子的h會對應到一條線。

139
00:13:20,190 --> 00:13:28,040
線的一邊是正的，一邊是負的。所以你看平面上有很多條線，所以例如說這條線說上面是正的-
，下面是負的。

140
00:13:28,040 --> 00:13:34,120
這條線是說右邊是正的，左邊是負的。每一條線就會有不一樣的這個預測。

141
00:13:34,120 --> 00:13:42,120
好，每一條線是不一樣的，所以呢其實另外一個角度來看，如果從幾何的角度來看的話。

142
00:13:42,120 --> 00:13:50,690
我們剛才說的perceptron說的這個感知器。實際上就是
平面上的一條一條線，所以我們有說有它叫linear classifiers。

143
00:13:50,690 --> 00:13:57,470
線性的分類性，我們這個說說是要回答是非題，其實就是分成兩類。

144
00:13:57,470 --> 00:14:01,980
線性的分類性，用一條線來代表分類性。

145
00:14:01,980 --> 00:14:08,770
那在這個更高維的話，可能就是這個平面或高維度的平面。

146
00:14:08,770 --> 00:14:12,770
那這個跟線實際上在幾何上是有類似的意義的。

147
00:14:12,770 --> 00:14:21,270
好，所以這個是跟大家介紹
這個perceptron感知器，這樣的一個hypothesis。

148
00:14:21,270 --> 00:14:25,805
那這個介紹完這個之後我們希望大家能夠想一想。

149
00:14:25,805 --> 00:14:34,240
說，好吧，如果我們今天把感知器這樣的東西 用在做垃圾郵件的這個預測。

150
00:14:34,240 --> 00:14:40,440
垃圾郵件要預測的話，我們可能說好，那我們就把郵件裡面的文字

151
00:14:40,440 --> 00:14:46,640
表示成一個長長的向量。有出現這個文字就說有這個字，沒有出現這個文字就說零，沒有這個字

152
00:14:46,640 --> 00:14:53,490
所以一個郵件可以看成一個這個長長的向量，如果我們使用感知器的話，那大家想一想

153
00:14:53,490 --> 00:15:02,830
感知器裡面不是有那些W嗎，哪一個維度 對哪一個字對應到的這個W會有比較大的權重。

154
00:15:02,830 --> 00:15:08,880
會有比較大的權重才是合理的。如果今天我們要做垃圾郵件的這個預測的話。

155
00:15:08,880 --> 00:15:16,880
大家想一想之後希望大家得到的正確答案是2，什麼東西

156
00:15:16,880 --> 00:15:23,400
會有很大的權重？基本上是，我們有點像在算垃圾郵件的分數。

157
00:15:23,400 --> 00:15:29,920
所以有很大的權重就表示那些字在垃圾郵件裡面是常常出現的。這樣才會幫垃圾郵件的分-
數加分。

158
00:15:29,920 --> 00:15:36,375
我們列了所有單字裡面在2的選項，像這個fantastic，deal
或者是說drunk

159
00:15:36,375 --> 00:15:42,830
所以是在垃圾郵件裡面常常出現的字。所以它可能是會得到最大的權重。

