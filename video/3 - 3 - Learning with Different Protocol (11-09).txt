好，我們這邊再重新看一個這個我們看過的例子，說我們今天
要做錢幣的分類，我們說錢幣分類的時候，我們之前想一下，我們怎麼樣做到機器學習的。
我們先收集一堆錢，這些錢我們有它的大小，我們有它的重量。
然後把它都測量好，測量好以後還標說這個是1O
cents,還是1cents還是5cents。
然後我們把這些標好的資料，我們收集好的資料，統統好例如說我們收集了200顆錢，那這-
200筆資料
統統都餵給機器學習的演算法去得到一個g 這個g用在什麼，用在我們這個販賣機裡面。
以後每一個新的錢投下來
我們都用這個同樣的g，那這樣的學習方式叫做Batch。Batch是成批的我整批整批
把我的資料餵給機器學習演算法，一次塞給它好像丟一本書給它，它自己去裡面翻
自己去裡面學，這個是Batch的這個演算法。
但是演算法有很多的應用例如說好如果我們餵給機器一批說，欸如果我們已經收集好的這是一-
堆電子郵件。
它們到底是不是垃圾郵件這樣的資料，給機器的話，機器就會得到一個
我們未來可以使用的垃圾郵件的過濾器，或者醫院裡面有一堆病歷資料。這些
病人有沒有癌症我們已經知道了。餵給機器的話，我們就得到一個癌症的偵測或者分類器。
又或者今天不一定是監督式的，我們可能餵給機器一批這個銅板的資料，不告訴它這是什麼銅板
機器自己做分取的動作或者餵給它一堆病人的資料，不告訴它說這是什麼樣的病人
繼續做分取的動作。這樣都是成批成批，這個Batch Learning的方式。
那它是在機器學習裡面最典型最常見的一種有點像跟機器溝通的方式。
你怎麼餵資料給機器，就相當於人在教機器的時候跟機器溝通的這個方式。
好，那這是不是唯一的方式呢，我們想一個應用說我們的垃圾郵件裡面。
我們就真的說餵一批資料給機器，然後我們的垃圾郵件
篩選器就不動了嗎？我們已經選好g了，g就不動了嗎？
好像現在我們日常生活中的應用不見得是這個樣子。
我們的應用可能是什麼樣子，應用可能說今天我收到一封郵件。
收到一封郵件的時候，我說欸那垃圾郵件過濾器它到底是不是垃圾郵件，它就自動幫我判斷了。
自動幫我判斷以後，如果它判斷錯了，我就告訴它說你判斷錯了，它說這是垃圾郵件，我說-
這不是。
或者他說這不是垃圾郵件，我說這是。好，所以這樣一個流程。
垃圾郵件一封一封的進來。然後我們一封一封的告訴機器我們要的是什麼，當然我們希望機器-
越來越正確。
有兩個事情，一個是機器學習的這個hypothesis，這個g是一直在變動的。
一封新進來，我們告訴它新的資訊，它可能就要變動一下，下次希望能夠告訴我正確的答案。
然後再來我們是一封一封的 把我們的資料一筆一筆的告訴它，我們並不是說
我今天已經收集了一千封郵件，它是不是垃圾郵件的資料，我整個餵給機器，沒有，它是一封-
一封的進來。
z一封一封的進來之後，我們一封一封的告訴它答案。
這樣子循序機器學習的方式，我們一般叫做online
learning或者叫做線上學習。
也就是它是這個按順序按順序一筆一筆來的。
跟我們之前學過的機器學習的一些方法有什麼關係呢？
例如說，大家記得Perceptron
Learning Algorithm，我們上一次學的
它做什麼事情，它每一輪選一個出來看看對不對。
對的話就不做事。不對的話就做一個更正的動作。
所以PLA這裡實際上很容易用在線上學習的這個溝通方式上面。
什麼意思呢，今天我也是每一次來一封新的。來一封新的
那麼我做了預測，做完預測以後如果我做的預測是對的，那就沒事。如果我做完預測是錯的
我就做像我們之前像PLA那樣的更新的動作。實際上可以證明這樣的
方法在PLA的變形在online
protocol 的這樣的溝通方式上面，也是有用的
PLA可以我們雖然說之前是說我們已經餵了100筆資料給它，然後電腦自己去選哪一個做-
錯，它就
修正哪一個做錯，它就修正。實際上在online這樣一筆一筆餵資料方式裡面，PLA也-
是有用的。
另外一個是什麼呢，另外一個我們之前提到是Reinforcement Learning
增強式的學習。
通常是一筆一筆的學到東西的，為什麼？因為我們每次都得到部分資訊
那你說這個我們不可能說一次告訴我們的狗三件事情，這個說坐下時是對的。
上廁所是對的，還是握手是對的。我們不可能一次告訴我們的狗很多資訊或者很多的X很多-
的輸入。
我們一次一定是它在這種狀況下，好，握手有沒有正確或者是不是一個很好的行為等等。
所以通常Reinforcement Learning的資料也是一筆一筆進來的。
它會比較接近在online protocol上面使用。
我們追求的事情是什麼？ 在這裡我們希望的是我們每一輪我們現在就不是出來一個單一的g。
我們每一輪都有一個g從g1，g2，g3一直下去。
那我們希望每一輪的g會越變越好，隨著新的資訊進來，每一輪的g能夠越變越好。
這就跟batch成批的方式還不一樣，成批的方式就是進去出來，一個g
我們希望這個g是好的。那這個online則是每一輪修正一下，修正一下，然後希望每一-
輪的g越變越好。
實際上大家可能可以發現，我剛才講protocol跟機器溝通的方式。
實際上對應到我們在機器學習裡面 到底我們從抽象上來的，哲學上來說的學習方式是什麼？
batch批次的方式比較像填鴨式教育。
我就丟一本書，裡面參考答案統統寫好，寫好以後叫你自己去讀，讀完以後，我問，你有沒有-
學到東西
online呢，online比較像老師在教書，老師教書就是一條一條教好。
我舉一個例子給你聽，告訴你這個例子的答案是什麼。我再舉一個例子給你聽，告訴你答案-
是什麼。
所以這樣一路的教下來，這是online的設定。
但是在這兩個設定裡面，大家注意到說，從機器角度來說
它都是被動的。人家餵什麼資料給它，它就做什麼事。不管是循序的也好，或成批的也好。
機器都是被動的。那在這幾年的機器學習裡面
有一個新的，廣為被人家研究的設定，是說我們能不能讓機器問問題？
就像我們上課的時候，我們希望學生問問題，我們希望什麼，學生問問題可以學的比較快。
所以我們給機器一個選擇，今天機器學習一個演算法比如我這個A的部份
可以跑去問F問題，什麼叫問問題？比較抽象的講法就是
我可以提出來今天有這個X,請問它的Y是多少？我有這個輸入，請問它的輸出是多少。
好，例如說最簡單的例子，如果我們今天做手寫辨識，也許機器會自己寫出一個字來
或者挑一個它還不會認得字。然後跟我們說這個字你寫的到底是9還是7。
這是機器從它的資料或從它的想像裡面去挑一個例子出來。
問你說它到底是什麼，這樣的設定，我們叫 active
learning主動學習。非常科普的講法它是讓機器有問問題的能力。
我們希望是什麼，我們希望機器如果能夠問問題的話那也許
我們一樣可能是一輪一輪有點像這個online這個線上的方式，一個一個問題問
然後問完這些問題後，因為機器問問題這些問題是有技巧的。
如果能夠有技巧問問題的話，也許我們能夠透過很少的問題。
就很快的可以學到東西，就像老師上課，老師上課希望大家問問題
然後問問題以後，也許大家可以很快的學到東西。這樣的方式我們叫做主動學習。
通常用在什麼地方，通常用在如果我們要取得lable，取得這些標記，很貴的場合。
大家之前記得我們講過 semi-supervised
也是類似的意思，我們為什麼不把資料全部標一標。
因為資料很多，沒有辦法全部標或者說要標很貴。如果是藥，要做藥物的測試很貴。
所以我們選擇不要全部標，我們只標一些些。
那麼active
learning主動學習也是一樣，我們如果要電腦來問，也許我們需要標註的資料
會比較少一些。
好，所以這是這部分給大家講我們怎麼樣用不同的跟機器溝通的方式來學習。
最常見的是batch，我們就填鴨式，通通都什麼東西都塞給機器。
我們也可以循序教它這是online，或者是讓機器有問問題的能力這是active。
也有很多不同的變化，我們這邊舉最典型的來跟大家講
我們在這門課裡面會著重在batch方式。就像我剛才講的PLA的例子，其實在batc-
h有很多的演算法
如果你學會之後要把它延伸到online或者其他的設定上也是
還蠻容易的這樣。所以我們先著重在batch的部分。
又到了小測驗的時間了，今天這個小測驗說的是：
有一個照相師他的硬碟里有很多很多的照片，他想要做照片自動分類的動作。但是呢？
他沒有辦法把這些照片一一的說，我手動來標。
x他就寫了一個演算，這個演算做的事情是這樣，他說這演算先法嘗試著自己
去做分類的動作，如果演算法發現說在分類的過程中
它覺得它沒有很大的信心，這張照片它可能會分錯，它就問人到底這張照片應該歸哪一類。
電腦會自動提出來說這張照片應該歸哪一類，請問這個對應到哪一個機器學習的算法。
大家想一想之後，我相信大家可能聽到關鍵字可能就想到了，關鍵字是什麼?問。
所以在這裡電腦會自動有問問題的能力，對應到的是active
learning的演算法。
實際上這裡描述的是我們在active learining 裡面用的典型的方式。
當電腦困惑的時候就提出問題，這跟我們上課對大家期望是一樣的，如果你對我們上課內容有-
什麼困惑的話，
歡迎你提出問題來，我們想辦法把這些東西講清楚。

