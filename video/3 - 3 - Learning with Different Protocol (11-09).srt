1
00:00:00,000 --> 00:00:05,640
好，我們這邊再重新看一個這個我們看過的例子，說我們今天

2
00:00:05,640 --> 00:00:11,280
要做錢幣的分類，我們說錢幣分類的時候，我們之前想一下，我們怎麼樣做到機器學習的。

3
00:00:11,280 --> 00:00:16,405
我們先收集一堆錢，這些錢我們有它的大小，我們有它的重量。

4
00:00:16,405 --> 00:00:21,530
然後把它都測量好，測量好以後還標說這個是1O
cents,還是1cents還是5cents。

5
00:00:21,530 --> 00:00:29,530
然後我們把這些標好的資料，我們收集好的資料，統統好例如說我們收集了200顆錢，那這-
200筆資料

6
00:00:29,530 --> 00:00:37,720
統統都餵給機器學習的演算法去得到一個g 這個g用在什麼，用在我們這個販賣機裡面。

7
00:00:37,720 --> 00:00:47,645
以後每一個新的錢投下來
我們都用這個同樣的g，那這樣的學習方式叫做Batch。Batch是成批的我整批整批

8
00:00:47,645 --> 00:00:57,510
把我的資料餵給機器學習演算法，一次塞給它好像丟一本書給它，它自己去裡面翻
自己去裡面學，這個是Batch的這個演算法。

9
00:00:57,510 --> 00:01:05,145
但是演算法有很多的應用例如說好如果我們餵給機器一批說，欸如果我們已經收集好的這是一-
堆電子郵件。

10
00:01:05,145 --> 00:01:12,780
它們到底是不是垃圾郵件這樣的資料，給機器的話，機器就會得到一個

11
00:01:12,780 --> 00:01:18,635
我們未來可以使用的垃圾郵件的過濾器，或者醫院裡面有一堆病歷資料。這些

12
00:01:18,635 --> 00:01:24,490
病人有沒有癌症我們已經知道了。餵給機器的話，我們就得到一個癌症的偵測或者分類器。

13
00:01:24,490 --> 00:01:31,530
又或者今天不一定是監督式的，我們可能餵給機器一批這個銅板的資料，不告訴它這是什麼銅板

14
00:01:31,530 --> 00:01:37,775
機器自己做分取的動作或者餵給它一堆病人的資料，不告訴它說這是什麼樣的病人

15
00:01:37,775 --> 00:01:44,020
繼續做分取的動作。這樣都是成批成批，這個Batch Learning的方式。

16
00:01:44,020 --> 00:01:49,850
那它是在機器學習裡面最典型最常見的一種有點像跟機器溝通的方式。

17
00:01:49,850 --> 00:01:55,680
你怎麼餵資料給機器，就相當於人在教機器的時候跟機器溝通的這個方式。

18
00:01:55,680 --> 00:02:03,500
好，那這是不是唯一的方式呢，我們想一個應用說我們的垃圾郵件裡面。

19
00:02:03,500 --> 00:02:13,110
我們就真的說餵一批資料給機器，然後我們的垃圾郵件
篩選器就不動了嗎？我們已經選好g了，g就不動了嗎？

20
00:02:13,110 --> 00:02:17,040
好像現在我們日常生活中的應用不見得是這個樣子。

21
00:02:17,040 --> 00:02:23,910
我們的應用可能是什麼樣子，應用可能說今天我收到一封郵件。

22
00:02:23,910 --> 00:02:31,080
收到一封郵件的時候，我說欸那垃圾郵件過濾器它到底是不是垃圾郵件，它就自動幫我判斷了。

23
00:02:31,080 --> 00:02:38,240
自動幫我判斷以後，如果它判斷錯了，我就告訴它說你判斷錯了，它說這是垃圾郵件，我說-
這不是。

24
00:02:38,240 --> 00:02:44,880
或者他說這不是垃圾郵件，我說這是。好，所以這樣一個流程。

25
00:02:44,880 --> 00:02:51,520
垃圾郵件一封一封的進來。然後我們一封一封的告訴機器我們要的是什麼，當然我們希望機器-
越來越正確。

26
00:02:51,520 --> 00:02:59,170
有兩個事情，一個是機器學習的這個hypothesis，這個g是一直在變動的。

27
00:02:59,170 --> 00:03:06,390
一封新進來，我們告訴它新的資訊，它可能就要變動一下，下次希望能夠告訴我正確的答案。

28
00:03:06,390 --> 00:03:14,815
然後再來我們是一封一封的 把我們的資料一筆一筆的告訴它，我們並不是說

29
00:03:14,815 --> 00:03:20,210
我今天已經收集了一千封郵件，它是不是垃圾郵件的資料，我整個餵給機器，沒有，它是一封-
一封的進來。

30
00:03:20,210 --> 00:03:23,560
z一封一封的進來之後，我們一封一封的告訴它答案。

31
00:03:23,560 --> 00:03:31,540
這樣子循序機器學習的方式，我們一般叫做online
learning或者叫做線上學習。

32
00:03:31,540 --> 00:03:35,610
也就是它是這個按順序按順序一筆一筆來的。

33
00:03:35,610 --> 00:03:42,401
跟我們之前學過的機器學習的一些方法有什麼關係呢？
例如說，大家記得Perceptron

34
00:03:42,401 --> 00:03:49,835
Learning Algorithm，我們上一次學的
它做什麼事情，它每一輪選一個出來看看對不對。

35
00:03:49,835 --> 00:03:54,510
對的話就不做事。不對的話就做一個更正的動作。

36
00:03:54,510 --> 00:04:01,310
所以PLA這裡實際上很容易用在線上學習的這個溝通方式上面。

37
00:04:01,310 --> 00:04:07,845
什麼意思呢，今天我也是每一次來一封新的。來一封新的

38
00:04:07,845 --> 00:04:14,380
那麼我做了預測，做完預測以後如果我做的預測是對的，那就沒事。如果我做完預測是錯的

39
00:04:14,380 --> 00:04:23,082
我就做像我們之前像PLA那樣的更新的動作。實際上可以證明這樣的
方法在PLA的變形在online

40
00:04:23,082 --> 00:04:26,900
protocol 的這樣的溝通方式上面，也是有用的

41
00:04:26,900 --> 00:04:33,960
PLA可以我們雖然說之前是說我們已經餵了100筆資料給它，然後電腦自己去選哪一個做-
錯，它就

42
00:04:33,960 --> 00:04:41,020
修正哪一個做錯，它就修正。實際上在online這樣一筆一筆餵資料方式裡面，PLA也-
是有用的。

43
00:04:41,020 --> 00:04:46,910
另外一個是什麼呢，另外一個我們之前提到是Reinforcement Learning
增強式的學習。

44
00:04:46,910 --> 00:04:54,070
通常是一筆一筆的學到東西的，為什麼？因為我們每次都得到部分資訊

45
00:04:54,070 --> 00:05:01,230
那你說這個我們不可能說一次告訴我們的狗三件事情，這個說坐下時是對的。

46
00:05:01,230 --> 00:05:08,510
上廁所是對的，還是握手是對的。我們不可能一次告訴我們的狗很多資訊或者很多的X很多-
的輸入。

47
00:05:08,510 --> 00:05:15,790
我們一次一定是它在這種狀況下，好，握手有沒有正確或者是不是一個很好的行為等等。

48
00:05:15,790 --> 00:05:20,075
所以通常Reinforcement Learning的資料也是一筆一筆進來的。

49
00:05:20,075 --> 00:05:24,360
它會比較接近在online protocol上面使用。

50
00:05:24,360 --> 00:05:32,490
我們追求的事情是什麼？ 在這裡我們希望的是我們每一輪我們現在就不是出來一個單一的g。

51
00:05:32,490 --> 00:05:38,600
我們每一輪都有一個g從g1，g2，g3一直下去。

52
00:05:38,600 --> 00:05:44,710
那我們希望每一輪的g會越變越好，隨著新的資訊進來，每一輪的g能夠越變越好。

53
00:05:44,710 --> 00:05:51,440
這就跟batch成批的方式還不一樣，成批的方式就是進去出來，一個g

54
00:05:51,440 --> 00:05:58,170
我們希望這個g是好的。那這個online則是每一輪修正一下，修正一下，然後希望每一-
輪的g越變越好。

55
00:05:58,170 --> 00:06:05,890
實際上大家可能可以發現，我剛才講protocol跟機器溝通的方式。

56
00:06:05,890 --> 00:06:14,040
實際上對應到我們在機器學習裡面 到底我們從抽象上來的，哲學上來說的學習方式是什麼？

57
00:06:14,040 --> 00:06:17,830
batch批次的方式比較像填鴨式教育。

58
00:06:17,830 --> 00:06:25,420
我就丟一本書，裡面參考答案統統寫好，寫好以後叫你自己去讀，讀完以後，我問，你有沒有-
學到東西

59
00:06:25,420 --> 00:06:31,390
online呢，online比較像老師在教書，老師教書就是一條一條教好。

60
00:06:31,390 --> 00:06:37,360
我舉一個例子給你聽，告訴你這個例子的答案是什麼。我再舉一個例子給你聽，告訴你答案-
是什麼。

61
00:06:37,360 --> 00:06:41,090
所以這樣一路的教下來，這是online的設定。

62
00:06:41,090 --> 00:06:47,780
但是在這兩個設定裡面，大家注意到說，從機器角度來說

63
00:06:47,780 --> 00:06:53,790
它都是被動的。人家餵什麼資料給它，它就做什麼事。不管是循序的也好，或成批的也好。

64
00:06:53,790 --> 00:06:59,595
機器都是被動的。那在這幾年的機器學習裡面

65
00:06:59,595 --> 00:07:05,400
有一個新的，廣為被人家研究的設定，是說我們能不能讓機器問問題？

66
00:07:05,400 --> 00:07:13,250
就像我們上課的時候，我們希望學生問問題，我們希望什麼，學生問問題可以學的比較快。

67
00:07:13,250 --> 00:07:20,390
所以我們給機器一個選擇，今天機器學習一個演算法比如我這個A的部份

68
00:07:20,390 --> 00:07:27,440
可以跑去問F問題，什麼叫問問題？比較抽象的講法就是

69
00:07:27,440 --> 00:07:34,490
我可以提出來今天有這個X,請問它的Y是多少？我有這個輸入，請問它的輸出是多少。

70
00:07:34,490 --> 00:07:41,205
好，例如說最簡單的例子，如果我們今天做手寫辨識，也許機器會自己寫出一個字來

71
00:07:41,205 --> 00:07:47,920
或者挑一個它還不會認得字。然後跟我們說這個字你寫的到底是9還是7。

72
00:07:47,920 --> 00:07:53,370
這是機器從它的資料或從它的想像裡面去挑一個例子出來。

73
00:07:53,370 --> 00:07:59,633
問你說它到底是什麼，這樣的設定，我們叫 active

74
00:07:59,633 --> 00:08:04,380
learning主動學習。非常科普的講法它是讓機器有問問題的能力。

75
00:08:04,380 --> 00:08:09,650
我們希望是什麼，我們希望機器如果能夠問問題的話那也許

76
00:08:09,650 --> 00:08:17,490
我們一樣可能是一輪一輪有點像這個online這個線上的方式，一個一個問題問

77
00:08:17,490 --> 00:08:21,775
然後問完這些問題後，因為機器問問題這些問題是有技巧的。

78
00:08:21,775 --> 00:08:26,060
如果能夠有技巧問問題的話，也許我們能夠透過很少的問題。

79
00:08:26,060 --> 00:08:31,690
就很快的可以學到東西，就像老師上課，老師上課希望大家問問題

80
00:08:31,690 --> 00:08:37,320
然後問問題以後，也許大家可以很快的學到東西。這樣的方式我們叫做主動學習。

81
00:08:37,320 --> 00:08:44,710
通常用在什麼地方，通常用在如果我們要取得lable，取得這些標記，很貴的場合。

82
00:08:44,710 --> 00:08:51,695
大家之前記得我們講過 semi-supervised
也是類似的意思，我們為什麼不把資料全部標一標。

83
00:08:51,695 --> 00:08:58,680
因為資料很多，沒有辦法全部標或者說要標很貴。如果是藥，要做藥物的測試很貴。

84
00:08:58,680 --> 00:09:03,825
所以我們選擇不要全部標，我們只標一些些。

85
00:09:03,825 --> 00:09:08,970
那麼active
learning主動學習也是一樣，我們如果要電腦來問，也許我們需要標註的資料

86
00:09:08,970 --> 00:09:14,680
會比較少一些。

87
00:09:14,680 --> 00:09:20,390
好，所以這是這部分給大家講我們怎麼樣用不同的跟機器溝通的方式來學習。

88
00:09:20,390 --> 00:09:25,525
最常見的是batch，我們就填鴨式，通通都什麼東西都塞給機器。

89
00:09:25,525 --> 00:09:30,660
我們也可以循序教它這是online，或者是讓機器有問問題的能力這是active。

90
00:09:30,660 --> 00:09:36,370
也有很多不同的變化，我們這邊舉最典型的來跟大家講

91
00:09:36,370 --> 00:09:43,005
我們在這門課裡面會著重在batch方式。就像我剛才講的PLA的例子，其實在batc-
h有很多的演算法

92
00:09:43,005 --> 00:09:49,640
如果你學會之後要把它延伸到online或者其他的設定上也是

93
00:09:49,640 --> 00:09:54,750
還蠻容易的這樣。所以我們先著重在batch的部分。

94
00:09:54,750 --> 00:10:02,750
又到了小測驗的時間了，今天這個小測驗說的是：

95
00:10:02,750 --> 00:10:08,060
有一個照相師他的硬碟里有很多很多的照片，他想要做照片自動分類的動作。但是呢？

96
00:10:08,060 --> 00:10:13,370
他沒有辦法把這些照片一一的說，我手動來標。

97
00:10:13,370 --> 00:10:22,770
x他就寫了一個演算，這個演算做的事情是這樣，他說這演算先法嘗試著自己
去做分類的動作，如果演算法發現說在分類的過程中

98
00:10:22,770 --> 00:10:30,035
它覺得它沒有很大的信心，這張照片它可能會分錯，它就問人到底這張照片應該歸哪一類。

99
00:10:30,035 --> 00:10:37,300
電腦會自動提出來說這張照片應該歸哪一類，請問這個對應到哪一個機器學習的算法。

100
00:10:37,300 --> 00:10:43,610
大家想一想之後，我相信大家可能聽到關鍵字可能就想到了，關鍵字是什麼?問。

101
00:10:43,610 --> 00:10:49,920
所以在這裡電腦會自動有問問題的能力，對應到的是active
learning的演算法。

102
00:10:49,920 --> 00:10:57,255
實際上這裡描述的是我們在active learining 裡面用的典型的方式。

103
00:10:57,255 --> 00:11:04,590
當電腦困惑的時候就提出問題，這跟我們上課對大家期望是一樣的，如果你對我們上課內容有-
什麼困惑的話，

104
00:11:04,590 --> 00:11:09,160
歡迎你提出問題來，我們想辦法把這些東西講清楚。

