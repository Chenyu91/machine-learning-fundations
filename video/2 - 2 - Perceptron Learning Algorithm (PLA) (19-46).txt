好!那所以我們現在知道了一個可能的hypothesis set，
可能的 大H長相。也就是說，我現在想像我大H就是平面上所有的線。
或者是說，我們在這個空間裡面所有可能的高平面。
好，那我們現在的問題是我們要怎樣設計一個演算法?
從這麼多的線裡面選一條最好的線出來。
大家記得我們上次提到演算法的目的就是要選一條最好的東西出來。我們怎麼選一條
最好的線?好，我們先回頭想想。我們覺得最好的線
是甚麼?我們覺得最好的就是那個理想上的那個F。
如果理想上的那個F，那就搞定啦!我們就收工回家吃飯啦!
可是當然我們不知道。
再三強調，我們不知道。如果我們知道的話，就沒有甚麼好做了。這學期不用上，大家下課-
，回家。
我們不知道F，但是我們最想要的線是跟F長得越接近
越好。那怎麼辦呢?我們只好回頭看看我們知道甚麼。
我們唯一知道的是我們的資料是從
F產生的。當我們的資料是從F產生的時候，那好吧!我們至少是不是可以先要求甚麼?
先要求我們的G跟F在我們所 看過的資料上要長得很接近，或最好是一模一樣的。
如果是一模一樣的話，那至少代表 好像說我看過的資料我都確定沒有問題了，沒看過的再說。
所以我們可不可以先要求這個?我們可以先在所有的線裡面找一條線，
這一條線說甚麼?這一條線說在我所看過的資料裡都跟F長得一模一樣。
甚麼叫做跟F長得一模一樣?也就是說我如果把G送來，送去預測資料裡面
這些X的話，我會就馬上得到這些Yn，我想要的這些 圈圈叉叉。我在我已經看過的資料
是準的。好!至少這是我們的出發點。這個出發點對不對，我們之後整學期的課會再跟大家
談這個，不過我們的出發點是這樣的。好，那我就問大家啦!接下來怎麼做?我要在
已經看過的資料裡面找一條線
滿足這個我的資料裡面如果是圈圈的，這一條線就要告訴我們圈圈。我的資料裡面如果是叉叉-
的，這一條就要告訴我
是叉叉。想一想搞不好還不是這麼容易。
為甚麼不這麼容易?因為你有無限多條線。
就算是二微空間，你的線在那邊轉來轉去，你有無限多條線。
如果是一個你有個很笨的收尋方法，搞不好你要收尋無限多種
可能性才會決定說哪一條線是你要的。那如果更高微度，可能就更困難。
所以這不是太容易。那我們現在要跟大家介紹的方法出發點是甚麼呢?那不然這樣好了，
我們先有一條線在手上，而這條線可能
不是那麼好或怎麼樣。我們可不可以想辦法有一條線在手上以後，修正一下它。
修正一下的意思就是說把這一條線越變越好，這跟人類學
是有一點像。我們一開始的時候可能這個不太會，可是越學越會。
好，所以我們有沒有辦法這樣?有一條線在手上，
這一條線可能會不太好，例如說它可能會在我們已知的資料上犯一點點錯誤。
像這個，那我們如果這一條線的話，這一個左邊右下方的圈圈是一個錯誤。
這一個錯誤怎麼樣?我們就想辦法來修正一下，我們把這個線
稍微移動一下。看看能不能完全修正這個錯誤，或至少減輕這個錯誤?
好，這個是我們接下來要跟大家 介紹的一個算法。我們說會怎麼樣?我們會一開始的時候
從這個一條線出發。我們說一開始，我們把這條線叫g0。
這一條線g0出發，這條線如果不夠好，我們就
把它變更好。直到我們覺得這個線好到不能再好，那我們才
結束。那我們從這個g0出發，那這個符號上期間我們簡單一點。
我們把這個g0用w0來代表。那記得每一個hypothesis在我們現在的討論裡面
對到一個高高的W，所以我們用w0來代表說我們一開始的線，
然後我們想辦法要讓這個線變得一次比一次
更好。好，那我們要怎樣子做？
現在跟大家介紹的方法是長這樣，我們一開始要一個W，那大家可能會很困惑W要長甚麼樣?
我說不管，不然就用全部都是0，代表你甚麼都不知道，就很難決定。
我等下會告訴大家怎麼樣能夠做更好。一開始
有個W之後，然後怎樣呢?如果這個線還不完美，
我們一定找得出某一個點， 資料裡面的某一個點。我們這個Xn,Yn，ok?然後這條線
犯的錯誤，我們就把這個點找出來，某一個點。
那這個某一個點我們把它叫做XnYn，然後後面括號一個小寫
t，因為我這個是一輪一輪的是小寫t代表我現在在哪一輪。
如果我現在的線把它叫做Wt， 在這個點上面，犯了錯誤。甚麼叫犯了錯誤?
好，我們現在還是要列得出來甚麼叫犯了錯誤?
犯了錯誤就是說我拿這條線
跟X去做類績去做預測，結果得到的符號，得到正負號。跟我想要的這個符號
不一樣，不一樣代表它犯了錯誤。對不對?
犯了錯誤我們怎樣呢?我們就想辦法來修正它。
修正，怎麼修正?我們這邊用一個示意圖跟大家講。我們等下會有更詳細的圖給大家看到底
是怎麼樣。修正有兩種，一種是 我要的符號是正的，結果它跟我說是負的。
那代表怎麼樣?我要的符號是正的， 它跟我說負的，代表我的這個W跟X的角度太大。
太大怎麼樣?
太大我們就把它轉回來，我就用W跟X 加起來，把它轉回來。轉回來的話，它可能在這個X上
說是這個。另外一種可能性，我要的是負的，結果它跟我說是正的。
那怎麼樣?
那代表W跟X的角度太小了。
我就把W減掉X，於是把W跟X轉開。轉開以後，
希望下一輪我的新的W就會把這個X弄得 對，或弄得更對些。所以我們就做一個這樣的修正。
如果我要這個，那我就把W轉得靠近X一點；
如果要負的，我就把W轉離X一點。所以這就是我們的式子，
W，然後怎麼轉，看X，然後看我要的符號是甚麼?如果是正的，那就接近X一點，如果是負-
的，就遠離X一點。
這是我更新的式子，我前面犯的錯，然後我做一個更新。
更新到甚麼時候呢?更新到我不再犯錯的時候。
所以它一直跑，跑到不再犯錯的
時候。不再犯錯的時候，我最後那條線完全沒有錯誤了，我就開開心心的說:『啊哈！找到這-
條線了!』 我就把這條線回傳回去說，這是我繼續學習的結果。
我繼續學習的結果說，我找到這條線。我們把這條線叫做W的PLA，
那PLA這三個字是Perceptron
Learning Algorithm。大家記得說perceptron，我們剛提的
感試器，然後它相對應的一個很著名的演算法叫做PLA，Perceptron
Learning Algorithm。
好!就這樣， 好簡單的演算法。對啊!沒錯，而且這個演算法我常常叫它甚麼?
叫它知錯能改演算法。我們大家看到這邊寫英文句子， A fault confessed
is half redressed.這一句話英文
英文比較好的同學可能就知道，這一句話其實對應到中文裡面就是所謂
知錯能改，善莫大焉。所以它知道錯，它找出一個犯錯地方
然後想辦法把它改過來，然後改到沒有錯誤。這一條線真是
完美，回傳回去。這個是perceptron learning
algorithm，PLA這個algorithm。
好，那所以我們剛才只是一個概略的
演算，實際上這個演算可能還有一些細節，例如說你要怎麼
簡單的判斷它就完全沒有犯錯?或你要怎麼簡單的找出來它到底還有沒有錯誤?
那一個常見的方式是說不然這樣好了，
我們就從1號、2號、3號、4號、5號，一直到n號點。例如說我有100個點就從1號到-
100號。
我一個一個輪流去看我的點，如果這個點都沒有錯，那我就開開心心看下一個點。
如果這個點犯了錯，我就做剛才的錯誤修正。
如果我100個人都拜訪過又繞回來後，發現都沒有再犯錯，那就表示我做完了。
這樣的方式我們一般叫做cyclic，跟PLA就是繞了一圈，跟PLA一樣的方式。
那是一個常見的方法來寫PLA。那當然
有很多其他不同的方法。那這個cycle，你可以說我就原來資料有
第一個到第一百個人，就從原來的一號到一百號。或者你先用亂數決定一個順序說
我第一個人跳第七個人再跳回第二個人，再跳第九個人，再跳第五個人，怎麼樣子跳過這一-
百個人?
這也可以，反正只要你能夠繞圈圈的做就可以了。
這些是常見的方式，因為可以很簡單的知道還有沒有人犯錯，然後來決定我們的演算法要-
不要停。
好，我這樣講，大家可能不太相信
說，誒，哪有這個三言兩語的演算法就可以做機器學習
的？我們來看看這樣的演算法能不能真正做到
很好。好，我們喂給機器這樣的資料，大家現在應該開始熟悉這樣的圖，這是一個
二維的資料，我們有一堆的
X，這些 X 對應到正一，所以它們是 圈圈。我們有一堆的，另外一堆的
X，這些 X 對應到負一，所以它們是叉叉。
機器看到的圖，機器看到的資料，就可以視覺化成這樣子
的圖。一堆圈圈，一堆叉叉。我們現在的問題是機器能不能透過我們剛才的那個方法找到-
那條線。
好，我們來看看，第一輪。所以機器就一個一個去找啦。
一個一個去找的時候，大家記得，它一開始沒有線，沒有線就好像看到什麼東西都是錯的。
所以它就找一個，找了第一個點說，我是錯的，我先來做修正。
做修正什麼意思？做修正就是把他原來沒有線沒有線那個零加上
好，這個點所代表的這個方向，它找到這個點剛好是正的，所以加上這個點所代表的方向實際-
上就是加上這個
方向，加到這個方向以後，它就得到一條新的線，這條線的法向量是什麼？
好，我們這邊其實是原點，所以這條線法向量大概是就是從原點一直到 X
的這個，這個長度。
所以大家等一下，在下一輪就會看到，下一輪的線會長什麼樣？會垂直于這個法向量
的樣子。好，說下一輪。好，說下一輪的線長這個樣子，
長這個樣子以後怎麼樣？我們看到說，這一條線
是不是已經完全沒有犯錯，這個圈圈是對的，這個圈圈是對的，這個圈圈是對的，都在藍-
色那邊。
這個叉叉是對的，這個叉叉是對的，這個叉叉是對的，都在紅色那邊。哪邊有錯？
這個錯，這個是個圈圈，結果它在紅色那邊。
好，所以呢，這個演算法就找找找找找，找到，哎呀，我是這裡犯的錯。
我是這裡犯的錯怎麼樣？知錯能改，知錯能改的時候， 我原來的方向是這條紅色的線，
我的錯誤發生在這條黑色的線，這條黑色的線告訴我說
我想要把這個黑色的線往正的那邊修正，也就是說，我做事情，做得更新是什麼？
把我原來的方向，跟這個這裡告訴我的方向做個
這個旋轉過來動作，所以我旋轉過來得到這條
紫色的線。所以大家在下一輪會看到，線就往這邊轉了，就會
轉過來。好，轉過來。好，大家看到，線轉過來了。這個這個藍色的這一條線，就這樣轉-
過來了。
轉過來以後，我們是修正完一個錯誤高枕無憂了，沒有。看起來這個線好像有一點怎麼樣？
轉太多了。轉太多什麼意思，轉過來，剛才這個圈圈對，
可是這個遙遠的這個叉叉變成在錯誤的那一邊了。
好，這個演算法就是這樣，找找找找找，找到發現，誒，這個叉叉有錯誤，叉叉有錯誤代表線-
還要繼續轉。
怎麼轉？這個時候，誒，不是要往叉叉這邊轉，因為往叉叉這邊轉它會
更正，要轉回去，往叉叉這個反方向轉回去。
轉回去以後，它得到一條這個新的線。所以再多了一個更新。
得到一條新的線。這一條線完美了嗎？還不
完美，哪裡錯了？誒，這邊有一個叉叉，它在錯誤的那一邊。
好，所以，這個演算法就決定那再修正一次，再修正一次怎麼樣？
往這個叉叉的反方向，這個線從紅色的轉成這個紫色的，
轉回來，轉回來又有人錯了，你說這個這個怎麼錯誤這麼多？
它一次只看一個點，所以有可能它這個這個，我們台語裡面叫做掠龜走鱉啊。
要抓這個龜，結果呢，逃走了這個鱉。所以
抓住一個點，結果逃走了另外一個點，好，所以這邊有一個錯，那它又要把它轉回
來。又轉回來。好，轉回來又轉太多了。於是這個又要轉過去，大家看到說，它其實一路在這-
邊轉轉轉轉轉轉，
不過轉轉轉轉轉的過程，到了這個第九
輪，經過一番更新，都是同樣的更新的過程，到這個第九輪，大家看
圈圈已經在這一邊了，叉叉已經在這一邊了。剩下這一個圈圈，第九個更新之後，
誒，很神奇的，我們找到了一條線，這一條線
所有的圈圈都在這一邊了，這邊可能看起來不太清楚，但是實際上這個圈圈是在這邊了。
所有的叉叉都在這邊，這是一條完美的線。
至少，在我們所看到的資料上，是一個完美的線。
好，大家，我們未來的注意力，我們會讓大家寫這個影像
如果你有興趣的話，也可以先寫寫看，這是一個非常簡潔的演算法。
我寫完的程式如果不含畫圖的部分，不到二十行。
然後但是，它很漂亮。咚咚咚
咚咚，誒，修正一下，修正一下，知錯能改一下，最後會找到一條
還不錯的線。好，當然你如果自己寫程式的話，我這邊有一個小小的
這個提醒，因為這邊，因為這個視覺效果，所以我偷偷做了一件事。
我讓這個 x，OK，就是我們的這個 這個特征，顧客特征這些，裡面的這些大小 都比
X0，大家記得我們我們強制把 X0 強制設成 1，我故意讓這個
X 裡面所有大小 都比 X0
來得大很多，這個視覺效果會比較好。那你如果自己做的話，可能這個如果你要看視覺效-
果，可能
要這樣做，那不管是不是這樣，實際上我們等一下會證明說這個演算法，都能夠幫我們找出
好的線來。好， 所以我們看到這個演算法真的會找出好的線來。
那現在問題是這樣，如果這個演算法停下來的時候，大家記得這個演算法什麼時候會停？
沒有錯誤的時候就會停，這個演算法停下來的時候就會找出好的線。
那現在問題我問大家，這個演算法一定會停下來嗎？
我們沒有跟大家說這個啊，我沒有跟大家說一定會停下來，我只是
show 一個例子， 我沒有跟大家說它一定會停下來，所以這是個問題。停下來
OK，
它如果會停下來一切都好辦，但是為什麼？為什麼它會停下來？它什麼時候不會停下來？
那所以另外一個角度是說，那好啊， 就算我們假設它停下來好了，我們拿到的
g 跟 f， 我們心裡最想要最渴望的那個 f 到底一不一樣？
好，如果停下來的話，g 跟 f 在
我們所看到的資料上是一樣的，只是確定這是我們的出發點。
但是，我們資料以外，沒有看過的東西呢？到底一不一樣呢？我們不知道。
那或者如果它不會停下來呢？那 g 跟 f 到底會不會一樣？我們就更不知道了。
好，所以這裡還是有一些問題的，我們等一下就會跟大家解答，但是我希望大家到這邊的時候
你腦袋裡覺得，啊，有個這麼神妙的一個算法。然後但是我們有一些些問題要
解決。我們等一下要跟大家證明的事情，我們要證明的事情，不是非常困難的
證明，但是我們要想辦法說的事情就是說在一些特定的這個狀況下，
如果你讓這個演算跑得夠久，它一定會停。
它一定會停就表示至少至少你在你所看見的資料上跟 f 是相近的。
那你所看見的資料以外的部分，再說差不多要過兩堂課以後再
說。好，所以這個，我們這個演算法很快的跟大家介紹過去，那我
希望能夠深化大家對這個演算法的了解，所以我們有一個這個
小小題目在這邊說，其實大家看到我們演算法的核心就只是兩條規則，
找出一個犯錯的點，如果我現在犯錯的點，就把它簡潔起見我們就叫 Xn，Yn，
然後呢，用這個犯錯的點來做某一種旋轉更新這個 W 的工作。
那我想要請大家看一看下面這四條式子，然後想一想說我就給大家這兩條規則。
你可以告訴我說這四條式子裡面，哪一條一定是對的。
好，我希望大家想一想以後 能夠得到這個正確的答案，我們給的參考答案是第三條。
第三條怎麼來的呢？如果我們把這個更新的式子 兩邊都乘上
YnXn， 兩邊都乘上 YnXn 的話怎麼樣，這邊有
YnXn，這邊有 YnXn， 然後這邊有一個正的東西，
好，這邊既然有一個正的東西就表示什麼？就表示 這一個的值會比這一個的值來得大。
所以這是第三條說的，第三條說，誒，這邊乘上 ynxn
會比這邊乘上 ynxn 來得大。
來得大什麼意思？ YnXn 是什麼啊？我們看看這裡，這邊有一個
W 乘上一個 Xn，這是什麼？這是我們那個分數，記不記得，OK，分數減掉這個這個
門檻值的那個東西，然後呢這個東西乘上 yn 以後會變大。
代表說，誒，如果它今天原來是這個， 這個負的，然後呢，這個會變得稍微靠近正一點。
所以他跟 yn 的符號會稍微符合一點，搞不好就變成全對了，搞不好還沒有那麼對。
好，所以這裡說的事情是，我們這個更新的規則實際上代表
了這個演算法真的在嘗試修正那條線，嘗試把線轉到正確的方向去。

