[音樂] [音樂]
[音樂] [音樂]
好 大家好 大家好 歡迎來到今天的機器學習課程
那今天我們要從上一次的故事繼續下去 我們上一次跟大家介紹了一個具體的機器學習的問題
然後以及他的內容的設定 那我們今天要繼續下去做什麼呢？ 我們今天要教大家說
到底我們怎麼樣可以 有一個機器學習的演算法來解決我們上一次提到的
要判斷銀行要不要給顧客信用卡這樣的問題 那麼複習一下我們上一次上了什麼
我們上一次說機器學習做的事情就是 有一個學習的演算法 我們叫做A
這個驗算法呢會看兩件事情 一件事情是什麼 是資料
我們叫做D 另外一件事情是一個hypothesis
set 這個這個假說的集合 那他要從這個hypothesis set裡面選一個
這個G 這個G會當做譬如說銀行最後使用的公式來這個
等於是學到的一個這個技能 好 那我們今天會來講講說到底機器
怎麼樣決定要不要發信用卡這一件事情 或者 更廣義的來說
機器怎麼解決這種 是非的題目 就像這個我們考試的時候
在做是非題一樣 我們今天要來學的是 怎麼樣的機器學習演算法 可以做是非題
好 所以我們稍微複習一下 我們上一次整個
機器學習的流程圖是怎麼樣 我們說 我們是從資料出發 那我們一個假設
資料從哪裡來的 資料從一個我們想學 但是我們不知道的這個公式
叫做F來的 我們有了這個資料以後 我們把這個資料餵給機器學習的演算法
那這個演算法 幫助我們做的事情是什麼 看這些資料 然後從所有的可能性
所有可能性 我們叫做大H 從所有大H裡面選一個G出來 然後
我們的希望是G要跟我們的想要的F這個越接近越好 那我們用這個信用卡的例子來做比喻說
那如果今天我們有一個信用卡的 申請人過來的時候 我們希望
這個申請人我們用這個小寫x來表示 我們希望這個最後的G能夠決定說
看了這個x 那它到底要給他信用卡還是不給他信用卡
我們用這個小寫的y來表示說要給還是不給 的這件事情
好 這是我們上一次提到的這個機器學習的設定 那我們現在進入什麼呢
我們現在進入說 好吧 那麼我們的大H到底會長什麼樣子
我們上一次只是很泛泛地講說 這些大H可能可以選
我們今天要跟大家介紹一個具體的大H的長相 好
那我這邊就來跟大家介紹一個模型 這個模型是說我們
怎麼樣拿到這個一組使用者的資料 我們怎麼樣評定要不要給他信用卡
我們可以把每一個使用者用一個向量來表示 我們說每一個使用者叫做x
我們可以把這個x想成一個向量 有好多個維度的向量 那例如說 第一個維度可能是他的
這個年紀 第二個維度可能是他的年薪 第三個維度可能是他在
工作有幾年了 那每個維度可能對我們有不同正面或負面的這個影響
決定說到底我們想不想給他信用卡 那我們想做的事情是這樣
我們把這些維度綜合地算起來 給使用者一個分數 然後呢這個分數會怎麼樣呢
如果這個分數超過了某個標準的話 我們就說 啊那給他信用卡沒有問題
如果這個分數沒有超過某個標準的話 我們就說不要給他信用卡好了
這就有點像你在考試的時候 那這個每一題每一個題目老師給你分數
把這些分數加加起來 如果你超過六十分的話 老師就說 啊你及格了
給你過關好了 如果沒有超過六十分 就說你不及格不要給你過關
這是類似的意思 好 那有了這樣的模型 所以我們說 每一個維度
我們說每一個維度我們用這個小Xi這個來代表 那它會乘上什麼呢
乘上這個維度的這個重要性 如果今天這個維度對我們來說很重要 我們可能這個
等於配分要多一點 如果這個維度對我們來說是這個正相關的
那可能是正面的重要 如果這個維度對我們來說是負相關的 例如說他欠的錢很多
那我們可能不要給他信用卡 那可能這個這裡的這個W會是這個負的或是比較小的 好
總之 就是這些東西加加起來 然後我們看看他最後得到的
分數幾分 好那在這樣的模型裡面呢 我們想像說 我們要做的事情是什麼
我們要電腦自動告訴我們說 要給信用卡 給信用卡是好的 還是不給信用卡
給信用卡是不好的 那我們當然可以用這個任意的這個數字或符號 來表示這件事情
那這裡為了數學簡單起見 我們用兩個數字來代表好或不好
好的我們叫+1 不好的我們叫-1 這樣表示有什麼好處呢
這樣表示的話 實際上我們發現一件事
我們要電腦做的決定 就是 先算出這一串分數
我們說這個W跟X 這些相乘這些分數通通算起來
算起來之後 減掉我們所設定的這個標準 設定的這個門檻值
然後怎麼樣 如果這個減掉以後是正的 我們就說 這個是好的 如果是負的
我們就說是不好的 所以這個相對來說 實際上就是取一個這個sin這樣
這個符號 可能是正負號的這個運算 所以我們就可以很簡潔的
把我們想要做的事情是什麼 把使用者的資料呢拿來 透過W來做一個加權
然後取一個總分 然後看看這個總分有沒有超出我們的門檻值
超出來我們就給+1 沒有超出來我們就給 沒有 就給-1
那你說 那如果剛好在門檻上面怎麼樣 通常這種事情很少發生
我們可以想像說我們就當做 就就就是一個這個這個特例的狀況
我們可以暫時不管它 事實上在我們未來講的故事裡面
大部份的時候這個剛好在這個門檻值上的情形 沒什麼重要性
或者是我們想像說不然那時候就丟個銅板決定好了 反正有時候是對的 有時候是錯的 好
那這樣的模型 這樣的反紅
有沒有注意到 我這裡用的是h 用的是小h 小h是什麼 小h是我們可能的公式
這個小h跟什麼東西有關 跟W有關 跟我們選的門檻有關
所以我們可以 不同的W 不同的門檻
就造出不同的h 好 那這樣的h 在這個
歷史上我們把這個叫做perceptron perceptron這個字
字面上的翻譯叫做感知器
那這個字的來源實際上 是非常早期的類神經網路的這些研究出來的 就是說
感知器就很像我們人體裡面的 一個神經元的數學模型一樣 我們這邊先不深究這件事情
我們就是說 好所以這是我們的一個hypothesis 可以注意到
hypothesis就是說電腦最後會猜測啊 猜測說是不是這是一個
可能的公式的長相 那這個h會用什麼來決定 用W跟
還有我們的 門檻值來決定 那這個W 通常我們會叫做位置
就是這個權重 就是每一個這個維度的這個權重
好 那所以我們的h長的是這樣 我們h是W
用W算出來的一個分數 然後再減掉門檻值 然後再取這個正負號
好你說這個 每次要寫這麼一長串很麻煩
所以我們這邊呢稍微跟大家說 我們會做一個這個簡化的動作
其實是符號上簡化 意思上沒有太簡化的地方 我們想要做什麼呢
我們想要把這個門檻值 okay 也當成是一個特殊的W
怎麼樣可以做到這件事情呢 大家看到說我們的這個式子 okay 這邊有這個W
然後有這個門檻值 我們如果把門檻值 我們要減掉這個門檻值
當做什麼呢 當作說 我們有一個這個負的
門檻值的這個 這個維度 然後呢 有一個
常數 這個常數叫做+1 然後順便把這個常數叫做X0 你說
我這個小x原來是一維二維一直到D維 我現在把它生出一個第0維來
生出一個第0維來有什麼好處 我就可以把這個負的門檻值
這個同等的叫做W0 那我就可以怎麼樣
我就可以把我原來這邊 前面有漂漂亮亮的WiXi
我可以把這個W0X0 收進來WiXi這邊 只需要放一個summation
放一個這個連加的這個符號 然後把連加的 起始點 從
原來是從1開始 現在改成用0開始 好 那這只是我們符號上做了一個事情
符號上做了這個事情有什麼好處呢 如果我今天把X 我們之前說X
1維到D維 現在加了第0維 好 想成一個這個高高的這個向量
那W我們也可以表示成一個高高的向量 所以這個summation這個連加的動作
其實就是兩個高高的向量的內積而已 好
我們這是符號上的簡化 我們不想要寫一堆summation
然後不想要特別寫一個 這個門檻值 所以我們就說 好 我們現在就想像 我們在處理什麼
我們在處理X 是這個顧客的資料，這個X顧客的資料是一個高高的向量。除了原來的資料以外
還有第0維。那w我們想要跟h所對應的這個w
也是一個高高的向量，它也有一個第0維，它的第0維會對應到我們原先想要的
負的這個門檻值。這只是一個符號。有了這個
符號以後呢，那我們就可以對這個符號做一些數學上的操作。
這樣子講大家可能還是覺得很抽象。
幹嘛要這個冒出一個，原來顧客這個資料我們知道
那冒出一個W這個符號，然後又說有一個這個h。
我們能不能有一些具體的想法說這個h長什麼樣子。
眼見為憑，所以我們給大家看看這個h長什麼樣子。
我們做什麼呢，我們畫一個二維的圖給大家看。
這個二維的圖上是什麼樣呢？這個二維圖上我們原來的每個X是二維的。
那如果我們加上這個剛才說X0那個維度的話，是一個這個假的這個三維，高高的這個向量。
所以他其實就是有什麼，我們如果看每一個h(x)都長的這樣，它有一個W0
有一個W1乘以x的第一個維度，有一個W2乘以x的第二個維度。
任何一條這樣的h我們可以把它畫出來。
像下面這樣畫出來，那麼怎麼畫呢？我給大家解釋一下。
我們的每一個原來顧客的向量，是一個二維的向量。
我們就把它們表示成平面上的一個點就是圈圈叉叉。統統都是一個點。
如果我們有更多維，當然就是在這個O幾的空間裡面。更多維的點，二維的我們比較好看一點。
那麼我們的Y在哪裡呢，我們想要的輸出，一般在資料裡面對應到想要輸出
我們一般把它叫lable，標籤，這個標籤在哪裡呢？這個標籤
我們畫成圈圈，還是叉叉，圈圈代表我們想要正1。
叉叉代表我們想要負1，圈圈代表正1叉叉代表負1。
所以我們就把這個平面然後就把圈圈叉叉弄出來了，那h是什麼？
h大家看看說，我們在取符號對不對
所以它的切換點是什麼，取正負號。
切換點是中間這個值等於0的時候，這是它的切換點，從正切換到負，等於0的時候，從正-
切換到負
那我今天有一個這個式子，這個式子是X1乘上什麼東西
加X2乘上什麼東西，然後加上一個這個截距然後等於0。
這在平面上是什麼？大家學過數學會說這就是條直線。
所以我如果把h畫出來給大家看的話，就是一條直線。
這條直線的一邊，這個h會說圈圈會說想要圈圈。
會說預測成圈圈。這個h的另外一邊我們的線會說叉叉。
所以我們的每個h實際上是對應到平面上面的一條線。
我們的每個資料裡面的每個X對應到一個點，Y對應到說我們的這個點上
畫圈圈還是叉叉。然後每個h我們剛才講的那樣子的h會對應到一條線。
線的一邊是正的，一邊是負的。所以你看平面上有很多條線，所以例如說這條線說上面是正的-
，下面是負的。
這條線是說右邊是正的，左邊是負的。每一條線就會有不一樣的這個預測。
好，每一條線是不一樣的，所以呢其實另外一個角度來看，如果從幾何的角度來看的話。
我們剛才說的perceptron說的這個感知器。實際上就是
平面上的一條一條線，所以我們有說有它叫linear classifiers。
線性的分類性，我們這個說說是要回答是非題，其實就是分成兩類。
線性的分類性，用一條線來代表分類性。
那在這個更高維的話，可能就是這個平面或高維度的平面。
那這個跟線實際上在幾何上是有類似的意義的。
好，所以這個是跟大家介紹
這個perceptron感知器，這樣的一個hypothesis。
那這個介紹完這個之後我們希望大家能夠想一想。
說，好吧，如果我們今天把感知器這樣的東西 用在做垃圾郵件的這個預測。
垃圾郵件要預測的話，我們可能說好，那我們就把郵件裡面的文字
表示成一個長長的向量。有出現這個文字就說有這個字，沒有出現這個文字就說零，沒有這個字
所以一個郵件可以看成一個這個長長的向量，如果我們使用感知器的話，那大家想一想
感知器裡面不是有那些W嗎，哪一個維度 對哪一個字對應到的這個W會有比較大的權重。
會有比較大的權重才是合理的。如果今天我們要做垃圾郵件的這個預測的話。
大家想一想之後希望大家得到的正確答案是2，什麼東西
會有很大的權重？基本上是，我們有點像在算垃圾郵件的分數。
所以有很大的權重就表示那些字在垃圾郵件裡面是常常出現的。這樣才會幫垃圾郵件的分-
數加分。
我們列了所有單字裡面在2的選項，像這個fantastic，deal
或者是說drunk
所以是在垃圾郵件裡面常常出現的字。所以它可能是會得到最大的權重。

